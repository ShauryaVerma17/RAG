{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to use FAISS to see if it makes a difference in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "#from langchain_text_splitters import TokenTextSplitter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = \"llama3\"; # Takes too much time to compute *sigh* we need better laptops\n",
    "llmmodel = Ollama(model=Model)\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"Oof that's a tough one, i don't really know this\"\n",
    "\n",
    "Context : {context}\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "promt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a md file instead of PDF so it is easier to split the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1161, which is longer than the specified 1000\n",
      "Created a chunk of size 2033, which is longer than the specified 1000\n",
      "Created a chunk of size 2603, which is longer than the specified 1000\n",
      "Created a chunk of size 1782, which is longer than the specified 1000\n",
      "Created a chunk of size 5099, which is longer than the specified 1000\n",
      "Created a chunk of size 2110, which is longer than the specified 1000\n",
      "Created a chunk of size 1398, which is longer than the specified 1000\n",
      "Created a chunk of size 3672, which is longer than the specified 1000\n",
      "Created a chunk of size 1463, which is longer than the specified 1000\n",
      "Created a chunk of size 1654, which is longer than the specified 1000\n",
      "Created a chunk of size 2628, which is longer than the specified 1000\n",
      "Created a chunk of size 1706, which is longer than the specified 1000\n",
      "Created a chunk of size 1773, which is longer than the specified 1000\n",
      "Created a chunk of size 2232, which is longer than the specified 1000\n",
      "Created a chunk of size 2492, which is longer than the specified 1000\n",
      "Created a chunk of size 2454, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = DirectoryLoader(path=\"testData\",glob=\"*.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"##\", chunk_size=1000, chunk_overlap=0)\n",
    "docs2 = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using faiss\n",
    "db2 = FAISS.from_documents(docs2, OllamaEmbeddings(model = Model))\n",
    "retriever2 = db2.as_retriever()\n",
    "# faiss_index.similarity_search(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = (\n",
    "    {\"context\" : itemgetter(\"question\") | retriever2 | format_docs , \"question\" : itemgetter(\"question\")}\n",
    "    | promt\n",
    "    | llmmodel \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The browser's high-level structure consists of:\n",
      "\n",
      "1. **User Interface**: Includes the address bar, back/forward button, bookmarking menu, etc.\n",
      "2. **Browser Engine**: Marshals actions between the UI and the rendering engine.\n",
      "3. **Rendering Engine**: Responsible for displaying requested content. For example, parses HTML and CSS, and displays the parsed content on the screen.\n",
      "4. **Networking**: Handles network calls such as HTTP requests, using different implementations for different platforms (behind a platform-independent interface).\n",
      "5. **UI Backend**: Used for drawing basic widgets like combo boxes and windows. This backend exposes a generic interface that is not platform specific. Underneath it uses operating system user interface methods.\n",
      "6. **JavaScript Engine**: Interpreter used to parse and execute JavaScript code.\n",
      "7. **Data Storage**: Persistence layer, responsible for storing data locally, such as cookies, and supporting storage mechanisms like localStorage, IndexedDB, and FileSystem.\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke({\"question\" : \"What is the browser's high level structure?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This splitting gives much better answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS lookup!\n",
      "\n",
      "In this context, the DNS (Domain Name System) lookup process happens when the browser tries to figure out the IP address for the entered domain. Here's a step-by-step breakdown:\n",
      "\n",
      "1. **Browser cache**: The browser checks its own cache of DNS records. If it has the desired record, it retrieves the associated IP address and proceeds.\n",
      "2. **OS cache**: If the browser cache doesn't have the record, the browser makes a system call to the OS (e.g., `gethostbyname` in Windows). The OS has its own cache of DNS records.\n",
      "3. **Router cache**: If the OS cache doesn't have the record, the request continues on to your router, which typically has its own DNS cache.\n",
      "4. **ISP DNS cache**: If the router's cache is empty, the request moves on to your ISP's DNS server, which has its own cache of DNS records.\n",
      "5. **Recursive search**: If the ISP's DNS cache is empty, it begins a recursive search from the root nameserver, through the `.com` top-level nameserver, to Google's nameserver.\n",
      "\n",
      "A recursive search diagram looks like this:\n",
      "\n",
      "<p align=\"center\"> <img src=\"img/Example_of_an_iterative_DNS_resolver.svg\" alt=\"Recursive DNS search\"/> </p>\n",
      "\n",
      "To mitigate potential bottlenecks in DNS lookups, techniques like round-robin DNS, load balancers, geographic DNS, and anycast are used. These approaches help distribute the traffic more evenly, reducing latency and improving overall performance.\n",
      "\n",
      "That's the basics of DNS lookup!\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke({\"question\" : \"Tell me about DNS Lookup\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, I can answer your question:\n",
      "\n",
      "Yes, I have information regarding rendering engines in browsers. In fact, the text mentions that when you touch the DOM in any way, you set a dirty bit on the whole tree that tells the browser it needs to figure out where everything goes again, which involves the rendering engine's layout algorithm (or more technically, its CSS recalc algorithm, then layout, then repaint, then re-compositing).\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke({\"question\" : \"Do you have information regarding rendering engines in browsers?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oof that's a tough one, I don't really know this! The context seems to be about how the web works and the history of the World Wide Web. There's no mention of Katappa or Bahubali, which appears to be a reference to an Indian movie. I'm not familiar with that topic, so I won't be able to answer your question.\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke({\"question\" : \"Why did katappa kill bahubali?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rendering engine is responsible for displaying requested content. It parses HTML and CSS, and displays the parsed content on the screen.\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke({\"question\" : \"What is a redering engine?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
